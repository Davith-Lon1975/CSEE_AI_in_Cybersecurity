{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cc74813",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from torchvision import datasets, transforms\n",
    "import syft as sy # Syft 0.5.0\n",
    "import numpy as np\n",
    "import torch # Torch 1.8.1\n",
    "import time\n",
    "import tenseal as ts\n",
    "from typing import Dict\n",
    "import opacus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08657b1",
   "metadata": {},
   "source": [
    "# Connect to Data Owner 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f89aa7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎤  🎸  ♪♪♪ Joining Duet ♫♫♫  🎻  🎹\n",
      "\n",
      "♫♫♫ >\u001b[93m DISCLAIMER\u001b[0m: \u001b[1mDuet is an experimental feature currently in beta.\n",
      "♫♫♫ > Use at your own risk.\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "    > ❤️ \u001b[91mLove\u001b[0m \u001b[92mDuet\u001b[0m? \u001b[93mPlease\u001b[0m \u001b[94mconsider\u001b[0m \u001b[95msupporting\u001b[0m \u001b[91mour\u001b[0m \u001b[93mcommunity!\u001b[0m\n",
      "    > https://github.com/sponsors/OpenMined\u001b[1m\n",
      "\n",
      "♫♫♫ > Punching through firewall to OpenGrid Network Node at:\n",
      "♫♫♫ > http://ec2-18-218-7-180.us-east-2.compute.amazonaws.com:5000\n",
      "♫♫♫ >\n",
      "♫♫♫ > ...waiting for response from OpenGrid Network... \n",
      "♫♫♫ > \u001b[92mDONE!\u001b[0m\n",
      "\n",
      "♫♫♫ > \u001b[95mSTEP 1:\u001b[0m Send the following Duet Client ID to your duet partner!\n",
      "♫♫♫ > Duet Client ID: \u001b[1m2cbbe8a7a91690e437adef830f822d7f\u001b[0m\n",
      "\n",
      "♫♫♫ > ...waiting for partner to connect...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\davit\\anaconda3\\envs\\NEW\\lib\\site-packages\\aiortc\\rtcdtlstransport.py:211: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
      "  _openssl_assert(lib.SSL_CTX_use_certificate(ctx, self._cert._x509) == 1)  # type: ignore\n",
      "C:\\Users\\davit\\anaconda3\\envs\\NEW\\lib\\site-packages\\aiortc\\rtcdtlstransport.py:186: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
      "  value=certificate_digest(self._cert._x509),  # type: ignore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "♫♫♫ > \u001b[92mCONNECTED!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "duet_1 = sy.duet(\"bfdb92b9d79738e803e4c55309e24d11\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae818c79",
   "metadata": {},
   "source": [
    "# Connect to Data Owner 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97654d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎤  🎸  ♪♪♪ Joining Duet ♫♫♫  🎻  🎹\n",
      "\n",
      "♫♫♫ >\u001b[93m DISCLAIMER\u001b[0m: \u001b[1mDuet is an experimental feature currently in beta.\n",
      "♫♫♫ > Use at your own risk.\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "    > ❤️ \u001b[91mLove\u001b[0m \u001b[92mDuet\u001b[0m? \u001b[93mPlease\u001b[0m \u001b[94mconsider\u001b[0m \u001b[95msupporting\u001b[0m \u001b[91mour\u001b[0m \u001b[93mcommunity!\u001b[0m\n",
      "    > https://github.com/sponsors/OpenMined\u001b[1m\n",
      "\n",
      "♫♫♫ > Punching through firewall to OpenGrid Network Node at:\n",
      "♫♫♫ > http://ec2-18-218-7-180.us-east-2.compute.amazonaws.com:5000\n",
      "♫♫♫ >\n",
      "♫♫♫ > ...waiting for response from OpenGrid Network... \n",
      "♫♫♫ > \u001b[92mDONE!\u001b[0m\n",
      "\n",
      "♫♫♫ > \u001b[95mSTEP 1:\u001b[0m Send the following Duet Client ID to your duet partner!\n",
      "♫♫♫ > Duet Client ID: \u001b[1mf18f4172e309823013f6db7b14fdbe96\u001b[0m\n",
      "\n",
      "♫♫♫ > ...waiting for partner to connect...\n",
      "\n",
      "♫♫♫ > \u001b[92mCONNECTED!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "duet_2 = sy.duet(\"ad563827b39279fd2de26bc0834e6c9b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f3f578",
   "metadata": {},
   "source": [
    "# Connect to Data Owner 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe27df94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎤  🎸  ♪♪♪ Joining Duet ♫♫♫  🎻  🎹\n",
      "\n",
      "♫♫♫ >\u001b[93m DISCLAIMER\u001b[0m: \u001b[1mDuet is an experimental feature currently in beta.\n",
      "♫♫♫ > Use at your own risk.\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "    > ❤️ \u001b[91mLove\u001b[0m \u001b[92mDuet\u001b[0m? \u001b[93mPlease\u001b[0m \u001b[94mconsider\u001b[0m \u001b[95msupporting\u001b[0m \u001b[91mour\u001b[0m \u001b[93mcommunity!\u001b[0m\n",
      "    > https://github.com/sponsors/OpenMined\u001b[1m\n",
      "\n",
      "♫♫♫ > Punching through firewall to OpenGrid Network Node at:\n",
      "♫♫♫ > http://ec2-18-218-7-180.us-east-2.compute.amazonaws.com:5000\n",
      "♫♫♫ >\n",
      "♫♫♫ > ...waiting for response from OpenGrid Network... \n",
      "♫♫♫ > \u001b[92mDONE!\u001b[0m\n",
      "\n",
      "♫♫♫ > \u001b[95mSTEP 1:\u001b[0m Send the following Duet Client ID to your duet partner!\n",
      "♫♫♫ > Duet Client ID: \u001b[1m3f7952a3101e0a7fada920a80d511c8d\u001b[0m\n",
      "\n",
      "♫♫♫ > ...waiting for partner to connect...\n",
      "\n",
      "♫♫♫ > \u001b[92mCONNECTED!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "duet_3 = sy.duet(\"705d560f9db03eef1cb78caa5c8698cf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08254d75",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "473a6b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class classify(sy.Module):\n",
    "    def __init__(self, torch_ref, num_classes=2):\n",
    "        super(classify, self).__init__(torch_ref=torch_ref)\n",
    "         \n",
    "        self.conv1=self.torch_ref.nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.bn1=self.torch_ref.nn.BatchNorm2d(num_features=12, momentum=0)\n",
    "        self.relu1=self.torch_ref.nn.ReLU()        \n",
    "        self.pool=self.torch_ref.nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv2=self.torch_ref.nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
    "        self.relu2=self.torch_ref.nn.ReLU()\n",
    "        self.conv3=self.torch_ref.nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
    "        self.bn3=self.torch_ref.nn.BatchNorm2d(num_features=32, momentum=0)\n",
    "        self.relu3=self.torch_ref.nn.ReLU()\n",
    "        self.fc=self.torch_ref.nn.Linear(in_features=32 * 112 * 112,out_features=num_classes)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output=self.conv1(input)\n",
    "        output=self.bn1(output)\n",
    "        output=self.relu1(output)\n",
    "        output=self.pool(output)\n",
    "        output=self.conv2(output)\n",
    "        output=self.relu2(output)\n",
    "        output=self.conv3(output)\n",
    "        output=self.bn3(output)\n",
    "        output=self.relu3(output)            \n",
    "        output=output.view(-1,32*112*112)\n",
    "        output=self.fc(output)\n",
    "            \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edfde2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model = classify(torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97547cb9",
   "metadata": {},
   "source": [
    "# Send Models to Data Owners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bbcc4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send to the domain owner 1\n",
    "remote_model_1 = local_model.send(duet_1)\n",
    "remote_model_1.train()\n",
    "remote_torch_1 = duet_1.torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b49bb5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_1 = remote_model_1.parameters()\n",
    "optimizer_1 = remote_torch_1.optim.Adam(params=params_1, lr=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14c19ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send to the domain owner 2\n",
    "remote_model_2 = local_model.send(duet_2)\n",
    "remote_torch_2 = duet_2.torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "550de48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_2 = remote_model_2.parameters()\n",
    "optimizer_2 = remote_torch_2.optim.Adam(params=params_2, lr=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79a79379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send to the domain owner 3\n",
    "remote_model_3 = local_model.send(duet_3)\n",
    "remote_torch_3 = duet_3.torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e810331",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_3 = remote_model_3.parameters()\n",
    "optimizer_3 = remote_torch_3.optim.Adam(params=params_3, lr=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb4fd29",
   "metadata": {},
   "source": [
    "# Define Training Function and Training Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4d27e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(iterations, model, torch_ref, optim, data_ptr, target_ptr):\n",
    "    losses = []\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        \n",
    "        output = model(data_ptr)\n",
    "        loss = torch_ref.nn.functional.cross_entropy(output, target_ptr.long())\n",
    "        loss.retain_grad()\n",
    "\n",
    "        loss_value = loss.get(\n",
    "            reason=\"To evaluate training progress\", request_block=True, timeout_secs=60, delete_obj=False\n",
    "        )\n",
    "        \n",
    "        print(\"Epoch\", i, \"loss\", loss_value)\n",
    "            \n",
    "        losses.append(loss_value)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optim.step()\n",
    "          \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9ed2f0",
   "metadata": {},
   "source": [
    "# Get Data Owner 1 Data Pointer and Label Pointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ea12511",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ptr_1 = duet_1.store[0]\n",
    "label_ptr_1 = duet_1.store[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d9f3aa",
   "metadata": {},
   "source": [
    "# Get Data Owner 2 Data Pointer and Label Pointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a20854e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ptr_2 = duet_2.store[0]\n",
    "label_ptr_2 = duet_2.store[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b78e5e",
   "metadata": {},
   "source": [
    "# Get Data Owner 3 Data Pointer and Label Pointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59ea4e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ptr_3 = duet_3.store[0]\n",
    "label_ptr_3 = duet_3.store[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a768a1",
   "metadata": {},
   "source": [
    "# Train Data Owner 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a47d9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss tensor(0.7901, requires_grad=True)\n",
      "Epoch 1 loss tensor(23565.4395, requires_grad=True)\n",
      "Epoch 2 loss tensor(4919.6392, requires_grad=True)\n",
      "Epoch 3 loss tensor(6221.1699, requires_grad=True)\n",
      "Epoch 4 loss tensor(4061.5581, requires_grad=True)\n",
      "Epoch 5 loss tensor(1458.7731, requires_grad=True)\n",
      "Epoch 6 loss tensor(357.0091, requires_grad=True)\n",
      "Epoch 7 loss tensor(613.0756, requires_grad=True)\n",
      "Epoch 8 loss tensor(500.4550, requires_grad=True)\n",
      "Epoch 9 loss tensor(311.9389, requires_grad=True)\n",
      "Epoch 10 loss tensor(164.3881, requires_grad=True)\n",
      "Epoch 11 loss tensor(62.8827, requires_grad=True)\n",
      "Epoch 12 loss tensor(7.9855, requires_grad=True)\n",
      "Epoch 13 loss tensor(46.2871, requires_grad=True)\n",
      "Epoch 14 loss tensor(45.6435, requires_grad=True)\n",
      "Epoch 15 loss tensor(22.4886, requires_grad=True)\n",
      "Epoch 16 loss tensor(13.3550, requires_grad=True)\n",
      "Epoch 17 loss tensor(19.0922, requires_grad=True)\n",
      "Epoch 18 loss tensor(23.2145, requires_grad=True)\n",
      "Epoch 19 loss tensor(25.4693, requires_grad=True)\n",
      "Epoch 20 loss tensor(28.3329, requires_grad=True)\n",
      "Epoch 21 loss tensor(30.6105, requires_grad=True)\n",
      "Epoch 22 loss tensor(25.3816, requires_grad=True)\n",
      "Epoch 23 loss tensor(22.6214, requires_grad=True)\n",
      "Epoch 24 loss tensor(20.5846, requires_grad=True)\n",
      "Epoch 25 loss tensor(15.4024, requires_grad=True)\n",
      "Epoch 26 loss tensor(15.6853, requires_grad=True)\n",
      "Epoch 27 loss tensor(11.5536, requires_grad=True)\n",
      "Epoch 28 loss tensor(15.7320, requires_grad=True)\n",
      "Epoch 29 loss tensor(8.7140, requires_grad=True)\n",
      "Epoch 30 loss tensor(10.2487, requires_grad=True)\n",
      "Epoch 31 loss tensor(6.3173, requires_grad=True)\n",
      "Epoch 32 loss tensor(11.4155, requires_grad=True)\n",
      "Epoch 33 loss tensor(3.9629, requires_grad=True)\n",
      "Epoch 34 loss tensor(6.6474, requires_grad=True)\n",
      "Epoch 35 loss tensor(3.5791, requires_grad=True)\n",
      "Epoch 36 loss tensor(5.5307, requires_grad=True)\n",
      "Epoch 37 loss tensor(2.8645, requires_grad=True)\n",
      "Epoch 38 loss tensor(2.6423, requires_grad=True)\n",
      "Epoch 39 loss tensor(2.0210, requires_grad=True)\n",
      "Epoch 40 loss tensor(2.0435, requires_grad=True)\n",
      "Epoch 41 loss tensor(2.2985, requires_grad=True)\n",
      "Epoch 42 loss tensor(2.2563, requires_grad=True)\n",
      "Epoch 43 loss tensor(1.4248, requires_grad=True)\n",
      "Epoch 44 loss tensor(1.6934, requires_grad=True)\n",
      "Epoch 45 loss tensor(1.3658, requires_grad=True)\n",
      "Epoch 46 loss tensor(0.7988, requires_grad=True)\n",
      "Epoch 47 loss tensor(1.1746, requires_grad=True)\n",
      "Epoch 48 loss tensor(1.4957, requires_grad=True)\n",
      "Epoch 49 loss tensor(1.1504, requires_grad=True)\n",
      "Epoch 50 loss tensor(1.4910, requires_grad=True)\n",
      "Epoch 51 loss tensor(0.9104, requires_grad=True)\n",
      "Epoch 52 loss tensor(1.8904, requires_grad=True)\n",
      "Epoch 53 loss tensor(0.7944, requires_grad=True)\n",
      "Epoch 54 loss tensor(0.7761, requires_grad=True)\n",
      "Epoch 55 loss tensor(1.2389, requires_grad=True)\n",
      "Epoch 56 loss tensor(1.0787, requires_grad=True)\n",
      "Epoch 57 loss tensor(0.7087, requires_grad=True)\n",
      "Epoch 58 loss tensor(1.1273, requires_grad=True)\n",
      "Epoch 59 loss tensor(0.7792, requires_grad=True)\n",
      "Epoch 60 loss tensor(0.7311, requires_grad=True)\n",
      "Epoch 61 loss tensor(0.6906, requires_grad=True)\n",
      "Epoch 62 loss tensor(0.6676, requires_grad=True)\n",
      "Epoch 63 loss tensor(0.6533, requires_grad=True)\n",
      "Epoch 64 loss tensor(0.6395, requires_grad=True)\n",
      "Epoch 65 loss tensor(0.6269, requires_grad=True)\n",
      "Epoch 66 loss tensor(0.6160, requires_grad=True)\n",
      "Epoch 67 loss tensor(0.6071, requires_grad=True)\n",
      "Epoch 68 loss tensor(0.6005, requires_grad=True)\n",
      "Epoch 69 loss tensor(0.5964, requires_grad=True)\n",
      "Epoch 70 loss tensor(0.5942, requires_grad=True)\n",
      "Epoch 71 loss tensor(0.5934, requires_grad=True)\n",
      "Epoch 72 loss tensor(0.5937, requires_grad=True)\n",
      "Epoch 73 loss tensor(0.5944, requires_grad=True)\n",
      "Epoch 74 loss tensor(0.5949, requires_grad=True)\n",
      "Epoch 75 loss tensor(0.5951, requires_grad=True)\n",
      "Epoch 76 loss tensor(0.5950, requires_grad=True)\n",
      "Epoch 77 loss tensor(0.5944, requires_grad=True)\n",
      "Epoch 78 loss tensor(0.5935, requires_grad=True)\n",
      "Epoch 79 loss tensor(0.5924, requires_grad=True)\n",
      "Epoch 80 loss tensor(0.5912, requires_grad=True)\n",
      "Epoch 81 loss tensor(0.5901, requires_grad=True)\n",
      "Epoch 82 loss tensor(0.5891, requires_grad=True)\n",
      "Epoch 83 loss tensor(0.5882, requires_grad=True)\n",
      "Epoch 84 loss tensor(0.5873, requires_grad=True)\n",
      "Epoch 85 loss tensor(0.5865, requires_grad=True)\n",
      "Epoch 86 loss tensor(0.5857, requires_grad=True)\n",
      "Epoch 87 loss tensor(0.5848, requires_grad=True)\n",
      "Epoch 88 loss tensor(0.5838, requires_grad=True)\n",
      "Epoch 89 loss tensor(0.5827, requires_grad=True)\n",
      "Epoch 90 loss tensor(0.5815, requires_grad=True)\n",
      "Epoch 91 loss tensor(0.5803, requires_grad=True)\n",
      "Epoch 92 loss tensor(0.5793, requires_grad=True)\n",
      "Epoch 93 loss tensor(0.5783, requires_grad=True)\n",
      "Epoch 94 loss tensor(0.5777, requires_grad=True)\n",
      "Epoch 95 loss tensor(0.5774, requires_grad=True)\n",
      "Epoch 96 loss tensor(0.5774, requires_grad=True)\n",
      "Epoch 97 loss tensor(0.5776, requires_grad=True)\n",
      "Epoch 98 loss tensor(0.5779, requires_grad=True)\n",
      "Epoch 99 loss tensor(0.5782, requires_grad=True)\n",
      "It took 365.01831007003784 seconds.\n"
     ]
    }
   ],
   "source": [
    "iterations = 100\n",
    "start = time.time()\n",
    "losses = train(iterations, remote_model_1, remote_torch_1, optimizer_1, data_ptr_1, label_ptr_1)\n",
    "print('It took', time.time()-start, 'seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af86c66f",
   "metadata": {},
   "source": [
    "# Train Data Owner 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7eba9b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss tensor(0.7936, requires_grad=True)\n",
      "Epoch 1 loss tensor(21373.2070, requires_grad=True)\n",
      "Epoch 2 loss tensor(4606.0483, requires_grad=True)\n",
      "Epoch 3 loss tensor(4739.9736, requires_grad=True)\n",
      "Epoch 4 loss tensor(3339.1079, requires_grad=True)\n",
      "Epoch 5 loss tensor(1069.8982, requires_grad=True)\n",
      "Epoch 6 loss tensor(171.9167, requires_grad=True)\n",
      "Epoch 7 loss tensor(172.1994, requires_grad=True)\n",
      "Epoch 8 loss tensor(156.0282, requires_grad=True)\n",
      "Epoch 9 loss tensor(54.3112, requires_grad=True)\n",
      "Epoch 10 loss tensor(24.1601, requires_grad=True)\n",
      "Epoch 11 loss tensor(3.6859, requires_grad=True)\n",
      "Epoch 12 loss tensor(34.8413, requires_grad=True)\n",
      "Epoch 13 loss tensor(12.3622, requires_grad=True)\n",
      "Epoch 14 loss tensor(38.4578, requires_grad=True)\n",
      "Epoch 15 loss tensor(47.0362, requires_grad=True)\n",
      "Epoch 16 loss tensor(43.6774, requires_grad=True)\n",
      "Epoch 17 loss tensor(38.4485, requires_grad=True)\n",
      "Epoch 18 loss tensor(88.0137, requires_grad=True)\n",
      "Epoch 19 loss tensor(61.1761, requires_grad=True)\n",
      "Epoch 20 loss tensor(42.4488, requires_grad=True)\n",
      "Epoch 21 loss tensor(57.4172, requires_grad=True)\n",
      "Epoch 22 loss tensor(49.1795, requires_grad=True)\n",
      "Epoch 23 loss tensor(35.8580, requires_grad=True)\n",
      "Epoch 24 loss tensor(24.4208, requires_grad=True)\n",
      "Epoch 25 loss tensor(40.6759, requires_grad=True)\n",
      "Epoch 26 loss tensor(41.8278, requires_grad=True)\n",
      "Epoch 27 loss tensor(23.8108, requires_grad=True)\n",
      "Epoch 28 loss tensor(53.1111, requires_grad=True)\n",
      "Epoch 29 loss tensor(20.0888, requires_grad=True)\n",
      "Epoch 30 loss tensor(53.7902, requires_grad=True)\n",
      "Epoch 31 loss tensor(17.4539, requires_grad=True)\n",
      "Epoch 32 loss tensor(35.7741, requires_grad=True)\n",
      "Epoch 33 loss tensor(14.1376, requires_grad=True)\n",
      "Epoch 34 loss tensor(22.9769, requires_grad=True)\n",
      "Epoch 35 loss tensor(11.2319, requires_grad=True)\n",
      "Epoch 36 loss tensor(18.8364, requires_grad=True)\n",
      "Epoch 37 loss tensor(13.7114, requires_grad=True)\n",
      "Epoch 38 loss tensor(11.2963, requires_grad=True)\n",
      "Epoch 39 loss tensor(10.1252, requires_grad=True)\n",
      "Epoch 40 loss tensor(10.4025, requires_grad=True)\n",
      "Epoch 41 loss tensor(9.4359, requires_grad=True)\n",
      "Epoch 42 loss tensor(4.4922, requires_grad=True)\n",
      "Epoch 43 loss tensor(11.6360, requires_grad=True)\n",
      "Epoch 44 loss tensor(6.1033, requires_grad=True)\n",
      "Epoch 45 loss tensor(12.1209, requires_grad=True)\n",
      "Epoch 46 loss tensor(4.0886, requires_grad=True)\n",
      "Epoch 47 loss tensor(20.9136, requires_grad=True)\n",
      "Epoch 48 loss tensor(6.3670, requires_grad=True)\n",
      "Epoch 49 loss tensor(19.2550, requires_grad=True)\n",
      "Epoch 50 loss tensor(3.8804, requires_grad=True)\n",
      "Epoch 51 loss tensor(15.8110, requires_grad=True)\n",
      "Epoch 52 loss tensor(10.2536, requires_grad=True)\n",
      "Epoch 53 loss tensor(6.5329, requires_grad=True)\n",
      "Epoch 54 loss tensor(14.5181, requires_grad=True)\n",
      "Epoch 55 loss tensor(3.8123, requires_grad=True)\n",
      "Epoch 56 loss tensor(7.6636, requires_grad=True)\n",
      "Epoch 57 loss tensor(9.4300, requires_grad=True)\n",
      "Epoch 58 loss tensor(1.3098, requires_grad=True)\n",
      "Epoch 59 loss tensor(3.7695, requires_grad=True)\n",
      "Epoch 60 loss tensor(5.6449, requires_grad=True)\n",
      "Epoch 61 loss tensor(2.0974, requires_grad=True)\n",
      "Epoch 62 loss tensor(1.4827, requires_grad=True)\n",
      "Epoch 63 loss tensor(4.4073, requires_grad=True)\n",
      "Epoch 64 loss tensor(1.6774, requires_grad=True)\n",
      "Epoch 65 loss tensor(1.3610, requires_grad=True)\n",
      "Epoch 66 loss tensor(2.1643, requires_grad=True)\n",
      "Epoch 67 loss tensor(2.3356, requires_grad=True)\n",
      "Epoch 68 loss tensor(1.4827, requires_grad=True)\n",
      "Epoch 69 loss tensor(0.8160, requires_grad=True)\n",
      "Epoch 70 loss tensor(1.2202, requires_grad=True)\n",
      "Epoch 71 loss tensor(1.2757, requires_grad=True)\n",
      "Epoch 72 loss tensor(1.0303, requires_grad=True)\n",
      "Epoch 73 loss tensor(0.8156, requires_grad=True)\n",
      "Epoch 74 loss tensor(0.8701, requires_grad=True)\n",
      "Epoch 75 loss tensor(0.9338, requires_grad=True)\n",
      "Epoch 76 loss tensor(0.9226, requires_grad=True)\n",
      "Epoch 77 loss tensor(0.8050, requires_grad=True)\n",
      "Epoch 78 loss tensor(0.7019, requires_grad=True)\n",
      "Epoch 79 loss tensor(0.6258, requires_grad=True)\n",
      "Epoch 80 loss tensor(0.5923, requires_grad=True)\n",
      "Epoch 81 loss tensor(0.5783, requires_grad=True)\n",
      "Epoch 82 loss tensor(0.5632, requires_grad=True)\n",
      "Epoch 83 loss tensor(0.5398, requires_grad=True)\n",
      "Epoch 84 loss tensor(0.5790, requires_grad=True)\n",
      "Epoch 85 loss tensor(0.5977, requires_grad=True)\n",
      "Epoch 86 loss tensor(0.5543, requires_grad=True)\n",
      "Epoch 87 loss tensor(0.4745, requires_grad=True)\n",
      "Epoch 88 loss tensor(0.4624, requires_grad=True)\n",
      "Epoch 89 loss tensor(0.4470, requires_grad=True)\n",
      "Epoch 90 loss tensor(0.4363, requires_grad=True)\n",
      "Epoch 91 loss tensor(0.4509, requires_grad=True)\n",
      "Epoch 92 loss tensor(0.4546, requires_grad=True)\n",
      "Epoch 93 loss tensor(0.4676, requires_grad=True)\n",
      "Epoch 94 loss tensor(0.4586, requires_grad=True)\n",
      "Epoch 95 loss tensor(0.4341, requires_grad=True)\n",
      "Epoch 96 loss tensor(0.4079, requires_grad=True)\n",
      "Epoch 97 loss tensor(0.3881, requires_grad=True)\n",
      "Epoch 98 loss tensor(0.3932, requires_grad=True)\n",
      "Epoch 99 loss tensor(0.4055, requires_grad=True)\n",
      "It took 358.19675850868225 seconds.\n"
     ]
    }
   ],
   "source": [
    "iterations = 100\n",
    "start = time.time()\n",
    "losses = train(iterations, remote_model_2, remote_torch_2, optimizer_2, data_ptr_2, label_ptr_2)\n",
    "print('It took', time.time()-start, 'seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327c0aba",
   "metadata": {},
   "source": [
    "# Train Data Owner 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf610c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss tensor(0.8109, requires_grad=True)\n",
      "Epoch 1 loss tensor(21367.7871, requires_grad=True)\n",
      "Epoch 2 loss tensor(5892.7070, requires_grad=True)\n",
      "Epoch 3 loss tensor(2540.3552, requires_grad=True)\n",
      "Epoch 4 loss tensor(2467.9924, requires_grad=True)\n",
      "Epoch 5 loss tensor(263.6607, requires_grad=True)\n",
      "Epoch 6 loss tensor(320.4272, requires_grad=True)\n",
      "Epoch 7 loss tensor(404.5284, requires_grad=True)\n",
      "Epoch 8 loss tensor(344.6219, requires_grad=True)\n",
      "Epoch 9 loss tensor(237.4182, requires_grad=True)\n",
      "Epoch 10 loss tensor(115.8260, requires_grad=True)\n",
      "Epoch 11 loss tensor(24.4386, requires_grad=True)\n",
      "Epoch 12 loss tensor(9.5104, requires_grad=True)\n",
      "Epoch 13 loss tensor(5.9565, requires_grad=True)\n",
      "Epoch 14 loss tensor(35.0970, requires_grad=True)\n",
      "Epoch 15 loss tensor(46.1302, requires_grad=True)\n",
      "Epoch 16 loss tensor(23.5955, requires_grad=True)\n",
      "Epoch 17 loss tensor(8.3163, requires_grad=True)\n",
      "Epoch 18 loss tensor(10.3554, requires_grad=True)\n",
      "Epoch 19 loss tensor(13.7634, requires_grad=True)\n",
      "Epoch 20 loss tensor(17.3598, requires_grad=True)\n",
      "Epoch 21 loss tensor(18.4156, requires_grad=True)\n",
      "Epoch 22 loss tensor(17.2674, requires_grad=True)\n",
      "Epoch 23 loss tensor(16.6694, requires_grad=True)\n",
      "Epoch 24 loss tensor(15.4732, requires_grad=True)\n",
      "Epoch 25 loss tensor(14.0781, requires_grad=True)\n",
      "Epoch 26 loss tensor(12.3844, requires_grad=True)\n",
      "Epoch 27 loss tensor(10.7539, requires_grad=True)\n",
      "Epoch 28 loss tensor(8.9712, requires_grad=True)\n",
      "Epoch 29 loss tensor(7.2369, requires_grad=True)\n",
      "Epoch 30 loss tensor(7.7322, requires_grad=True)\n",
      "Epoch 31 loss tensor(7.0516, requires_grad=True)\n",
      "Epoch 32 loss tensor(3.4199, requires_grad=True)\n",
      "Epoch 33 loss tensor(3.5121, requires_grad=True)\n",
      "Epoch 34 loss tensor(2.4758, requires_grad=True)\n",
      "Epoch 35 loss tensor(2.6835, requires_grad=True)\n",
      "Epoch 36 loss tensor(2.1165, requires_grad=True)\n",
      "Epoch 37 loss tensor(2.8306, requires_grad=True)\n",
      "Epoch 38 loss tensor(1.9461, requires_grad=True)\n",
      "Epoch 39 loss tensor(2.9201, requires_grad=True)\n",
      "Epoch 40 loss tensor(2.5274, requires_grad=True)\n",
      "Epoch 41 loss tensor(2.7859, requires_grad=True)\n",
      "Epoch 42 loss tensor(2.7219, requires_grad=True)\n",
      "Epoch 43 loss tensor(1.3343, requires_grad=True)\n",
      "Epoch 44 loss tensor(1.4144, requires_grad=True)\n",
      "Epoch 45 loss tensor(1.6552, requires_grad=True)\n",
      "Epoch 46 loss tensor(2.2828, requires_grad=True)\n",
      "Epoch 47 loss tensor(0.8309, requires_grad=True)\n",
      "Epoch 48 loss tensor(2.0393, requires_grad=True)\n",
      "Epoch 49 loss tensor(1.3174, requires_grad=True)\n",
      "Epoch 50 loss tensor(1.8583, requires_grad=True)\n",
      "Epoch 51 loss tensor(1.0736, requires_grad=True)\n",
      "Epoch 52 loss tensor(1.7179, requires_grad=True)\n",
      "Epoch 53 loss tensor(0.8012, requires_grad=True)\n",
      "Epoch 54 loss tensor(1.1589, requires_grad=True)\n",
      "Epoch 55 loss tensor(0.7552, requires_grad=True)\n",
      "Epoch 56 loss tensor(0.8992, requires_grad=True)\n",
      "Epoch 57 loss tensor(1.0764, requires_grad=True)\n",
      "Epoch 58 loss tensor(1.1469, requires_grad=True)\n",
      "Epoch 59 loss tensor(0.6689, requires_grad=True)\n",
      "Epoch 60 loss tensor(1.2583, requires_grad=True)\n",
      "Epoch 61 loss tensor(0.9378, requires_grad=True)\n",
      "Epoch 62 loss tensor(0.9731, requires_grad=True)\n",
      "Epoch 63 loss tensor(0.8300, requires_grad=True)\n",
      "Epoch 64 loss tensor(0.6569, requires_grad=True)\n",
      "Epoch 65 loss tensor(0.8083, requires_grad=True)\n",
      "Epoch 66 loss tensor(0.7358, requires_grad=True)\n",
      "Epoch 67 loss tensor(0.7342, requires_grad=True)\n",
      "Epoch 68 loss tensor(0.5575, requires_grad=True)\n",
      "Epoch 69 loss tensor(0.7459, requires_grad=True)\n",
      "Epoch 70 loss tensor(0.6483, requires_grad=True)\n",
      "Epoch 71 loss tensor(0.6147, requires_grad=True)\n",
      "Epoch 72 loss tensor(0.7319, requires_grad=True)\n",
      "Epoch 73 loss tensor(0.6531, requires_grad=True)\n",
      "Epoch 74 loss tensor(0.6764, requires_grad=True)\n",
      "Epoch 75 loss tensor(0.5253, requires_grad=True)\n",
      "Epoch 76 loss tensor(0.6203, requires_grad=True)\n",
      "Epoch 77 loss tensor(0.5642, requires_grad=True)\n",
      "Epoch 78 loss tensor(0.5113, requires_grad=True)\n",
      "Epoch 79 loss tensor(0.5380, requires_grad=True)\n",
      "Epoch 80 loss tensor(0.5076, requires_grad=True)\n",
      "Epoch 81 loss tensor(0.5144, requires_grad=True)\n",
      "Epoch 82 loss tensor(0.5547, requires_grad=True)\n",
      "Epoch 83 loss tensor(0.4676, requires_grad=True)\n",
      "Epoch 84 loss tensor(0.6284, requires_grad=True)\n",
      "Epoch 85 loss tensor(0.6752, requires_grad=True)\n",
      "Epoch 86 loss tensor(0.5390, requires_grad=True)\n",
      "Epoch 87 loss tensor(0.7088, requires_grad=True)\n",
      "Epoch 88 loss tensor(0.4770, requires_grad=True)\n",
      "Epoch 89 loss tensor(0.5784, requires_grad=True)\n",
      "Epoch 90 loss tensor(0.4466, requires_grad=True)\n",
      "Epoch 91 loss tensor(0.5702, requires_grad=True)\n",
      "Epoch 92 loss tensor(1.1357, requires_grad=True)\n",
      "Epoch 93 loss tensor(0.5591, requires_grad=True)\n",
      "Epoch 94 loss tensor(1.1842, requires_grad=True)\n",
      "Epoch 95 loss tensor(0.6867, requires_grad=True)\n",
      "Epoch 96 loss tensor(0.8413, requires_grad=True)\n",
      "Epoch 97 loss tensor(0.4697, requires_grad=True)\n",
      "Epoch 98 loss tensor(1.0375, requires_grad=True)\n",
      "Epoch 99 loss tensor(1.1088, requires_grad=True)\n",
      "It took 365.23575043678284 seconds.\n"
     ]
    }
   ],
   "source": [
    "iterations = 100\n",
    "start = time.time()\n",
    "losses = train(iterations, remote_model_3, remote_torch_3, optimizer_3, data_ptr_3, label_ptr_3)\n",
    "print('It took', time.time()-start, 'seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9bd763",
   "metadata": {},
   "source": [
    "# Get Updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfacf405",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_model_1_updates = remote_model_1.get(\n",
    "    request_block=True\n",
    ").state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d0bd1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv1.weight',\n",
       "              tensor([[[[-1.3486, -1.3437, -1.9394],\n",
       "                        [-1.2536, -1.1757, -1.5482],\n",
       "                        [-0.8120, -1.1406, -1.1071]],\n",
       "              \n",
       "                       [[-1.3561, -1.5246, -1.6725],\n",
       "                        [-1.1390, -1.2338, -1.8428],\n",
       "                        [-0.5872, -1.0722, -1.3489]],\n",
       "              \n",
       "                       [[-1.1927, -1.3567, -1.9442],\n",
       "                        [-1.2869, -1.4149, -1.7548],\n",
       "                        [-1.1513, -1.0102, -1.1319]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.0901, -0.5414,  2.1835],\n",
       "                        [ 0.1013,  0.4123,  2.3458],\n",
       "                        [ 0.2108,  0.5365,  2.0419]],\n",
       "              \n",
       "                       [[-1.2315, -0.6081,  1.9599],\n",
       "                        [-0.0711,  0.2793,  2.1101],\n",
       "                        [ 0.0682, -0.0783,  1.7752]],\n",
       "              \n",
       "                       [[-1.1769, -1.0139,  1.4225],\n",
       "                        [-0.3257,  0.0341,  2.0858],\n",
       "                        [-0.0821, -0.5292,  1.6918]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.4175, -0.8285, -0.8217],\n",
       "                        [-1.1848, -0.9410, -1.0189],\n",
       "                        [-1.4231, -1.3670, -0.9387]],\n",
       "              \n",
       "                       [[-1.4785, -1.0312, -1.0354],\n",
       "                        [-1.3150, -0.7135, -0.7360],\n",
       "                        [-1.2628, -1.4135, -1.0145]],\n",
       "              \n",
       "                       [[-0.7745, -1.0099, -0.8616],\n",
       "                        [-1.4943, -0.7660, -0.7751],\n",
       "                        [-1.0875, -0.9848, -0.7143]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.2636, -0.5758, -0.6678],\n",
       "                        [ 0.7537,  1.4566,  0.5060],\n",
       "                        [ 1.1330,  2.0699,  2.2423]],\n",
       "              \n",
       "                       [[-1.0963, -0.8935, -0.5889],\n",
       "                        [ 0.9324,  1.4210,  0.4655],\n",
       "                        [ 1.1847,  2.2279,  1.5256]],\n",
       "              \n",
       "                       [[-1.1115, -0.9519, -0.7399],\n",
       "                        [ 0.5636,  0.5602, -0.2018],\n",
       "                        [ 1.2438,  2.0342,  0.6723]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.8799, -1.2639, -1.8656],\n",
       "                        [-0.3477, -0.7709, -1.7324],\n",
       "                        [-0.6157, -0.9079, -1.9712]],\n",
       "              \n",
       "                       [[-0.7598, -1.3133, -1.6802],\n",
       "                        [-0.4081, -0.6077, -1.6664],\n",
       "                        [-0.4334, -0.8891, -1.7830]],\n",
       "              \n",
       "                       [[-0.6536, -1.6173, -1.7323],\n",
       "                        [-0.4349, -0.9539, -1.6596],\n",
       "                        [-0.3395, -1.1235, -1.9625]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.7510, -1.5923, -1.4981],\n",
       "                        [-1.7014, -0.4970, -0.6289],\n",
       "                        [-1.8972, -0.0946, -0.2693]],\n",
       "              \n",
       "                       [[-2.0062, -1.6787, -1.6039],\n",
       "                        [-1.9052, -0.6408, -0.3363],\n",
       "                        [-2.0623, -0.1423, -0.0117]],\n",
       "              \n",
       "                       [[-1.5581, -0.3968,  0.1260],\n",
       "                        [-1.1647,  0.9226,  0.5379],\n",
       "                        [-1.0298,  0.3523,  0.5045]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0310,  1.5026,  1.3067],\n",
       "                        [ 1.0273,  1.1460,  0.9713],\n",
       "                        [ 0.8941,  1.4496,  0.7835]],\n",
       "              \n",
       "                       [[ 1.0533,  1.3866,  1.4715],\n",
       "                        [ 0.8297,  1.4131,  0.9144],\n",
       "                        [ 0.8656,  1.3849,  0.8823]],\n",
       "              \n",
       "                       [[ 0.8265,  1.4418,  1.2290],\n",
       "                        [ 1.0544,  1.2734,  1.0775],\n",
       "                        [ 0.8313,  1.2415,  0.8781]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.5447, -1.8191, -1.1383],\n",
       "                        [-3.2000, -0.7285, -1.1617],\n",
       "                        [-2.0089, -0.4867, -0.7709]],\n",
       "              \n",
       "                       [[-1.5761, -0.5427, -0.9492],\n",
       "                        [-1.5223, -0.0716, -0.6628],\n",
       "                        [-1.8252, -0.3749, -0.8734]],\n",
       "              \n",
       "                       [[-1.5002,  0.0736, -0.2267],\n",
       "                        [-0.7566,  0.3472,  0.1343],\n",
       "                        [-1.0812, -0.5097, -0.4950]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.4166,  1.1218,  0.8207],\n",
       "                        [ 1.1283,  1.4455,  1.0577],\n",
       "                        [ 0.3854, -0.3566,  0.6990]],\n",
       "              \n",
       "                       [[ 1.1231,  1.1251,  0.8784],\n",
       "                        [ 1.3730,  1.1716,  0.9522],\n",
       "                        [ 0.5720,  0.1147,  0.9316]],\n",
       "              \n",
       "                       [[ 1.3607,  1.3420,  1.0628],\n",
       "                        [ 1.1056,  1.3695,  0.9099],\n",
       "                        [ 0.2665,  0.2124,  0.9271]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.7295, -1.6790, -1.1214],\n",
       "                        [-2.0275, -0.8880, -0.7291],\n",
       "                        [-1.2034, -0.7196, -0.4496]],\n",
       "              \n",
       "                       [[-1.5895, -1.4592, -0.9332],\n",
       "                        [-2.1267, -0.7091, -0.4505],\n",
       "                        [-1.3643, -0.5188, -0.4874]],\n",
       "              \n",
       "                       [[-1.3460,  0.1449,  0.1415],\n",
       "                        [-1.5319, -0.0573, -0.3413],\n",
       "                        [-1.0187, -0.3353, -0.5650]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.0989, -1.7519, -1.6164],\n",
       "                        [-1.3418, -1.2865, -1.2535],\n",
       "                        [-1.5894, -1.3990, -1.5916]],\n",
       "              \n",
       "                       [[-1.3888, -1.3146, -1.3403],\n",
       "                        [-0.7467, -1.1923, -1.2350],\n",
       "                        [-1.5418, -1.3774, -1.6013]],\n",
       "              \n",
       "                       [[-0.0244, -1.2246, -1.3535],\n",
       "                        [-0.1410, -1.0386, -1.1561],\n",
       "                        [-1.3838, -1.2110, -1.2802]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3756, -0.9959, -1.4712],\n",
       "                        [ 0.4791, -0.0462, -1.4767],\n",
       "                        [ 0.6218, -1.2128, -1.5564]],\n",
       "              \n",
       "                       [[ 0.0347, -0.6956, -1.6423],\n",
       "                        [ 0.5365,  0.2468, -1.3435],\n",
       "                        [ 0.3081, -1.0266, -1.5370]],\n",
       "              \n",
       "                       [[ 0.0401, -1.4585, -1.6262],\n",
       "                        [ 0.3904, -0.0829, -1.5321],\n",
       "                        [ 0.2896, -2.1062, -1.5358]]]])),\n",
       "             ('conv1.bias',\n",
       "              tensor([ 1.1083, -1.1215,  0.7923, -1.4860, -1.0539, -1.6614, -1.2479, -2.3305,\n",
       "                       0.7210, -1.0301, -0.7398,  1.2758])),\n",
       "             ('bn1.weight',\n",
       "              tensor([ 0.4479, -0.5740,  0.2212, -0.7535, -0.2951,  2.4822,  0.6878,  1.8996,\n",
       "                       1.8198,  1.8942, -0.0499, -1.2818])),\n",
       "             ('bn1.bias',\n",
       "              tensor([-0.9081, -2.0852, -1.0785, -1.7973, -2.0622,  1.0957,  0.7336,  0.3223,\n",
       "                       0.9085,  0.4066, -2.5376, -2.2301])),\n",
       "             ('bn1.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('bn1.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('bn1.num_batches_tracked', tensor(100)),\n",
       "             ('conv2.weight',\n",
       "              tensor([[[[ 1.7012,  1.7946,  1.7744],\n",
       "                        [ 1.8901,  1.8722,  1.6337],\n",
       "                        [ 1.7341,  1.7540,  1.8383]],\n",
       "              \n",
       "                       [[ 0.5450,  0.8136,  0.8461],\n",
       "                        [ 0.4658,  0.8924,  0.7747],\n",
       "                        [ 0.7710,  0.5804,  0.7021]],\n",
       "              \n",
       "                       [[ 1.6900,  1.6602,  1.5615],\n",
       "                        [ 1.2423,  1.4631,  1.6443],\n",
       "                        [ 1.1622,  1.4549,  1.4823]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.8659,  1.8469,  1.8612],\n",
       "                        [ 1.7714,  1.9113,  1.8401],\n",
       "                        [ 1.8152,  1.8304,  1.7784]],\n",
       "              \n",
       "                       [[ 1.4859,  1.6809,  2.0077],\n",
       "                        [ 1.9723,  2.0151,  1.9733],\n",
       "                        [ 1.5248,  1.4554,  1.4625]],\n",
       "              \n",
       "                       [[ 1.8383,  1.3662,  1.2980],\n",
       "                        [ 1.8533,  1.8047,  1.7893],\n",
       "                        [ 1.8239,  1.4254,  1.3549]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0468,  2.3338,  2.8054],\n",
       "                        [ 1.0870,  2.4610,  3.0230],\n",
       "                        [ 1.0757,  2.3508,  2.8734]],\n",
       "              \n",
       "                       [[-0.9315, -0.9109, -1.6145],\n",
       "                        [-1.1347, -1.2126, -1.5740],\n",
       "                        [-1.2666, -1.2421, -1.6074]],\n",
       "              \n",
       "                       [[ 1.2073,  2.0982,  2.9300],\n",
       "                        [ 1.0111,  1.8332,  2.9473],\n",
       "                        [ 1.1494,  2.1523,  2.8379]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.8098,  0.7856,  1.5097],\n",
       "                        [-1.0011,  0.7236,  1.5968],\n",
       "                        [-0.8794,  0.6223,  1.6199]],\n",
       "              \n",
       "                       [[ 1.6847,  2.1977,  2.5126],\n",
       "                        [ 2.2526,  2.3055,  3.2716],\n",
       "                        [ 1.1652,  2.0865,  2.4965]],\n",
       "              \n",
       "                       [[ 1.4016,  1.5173,  1.8276],\n",
       "                        [ 1.3464,  1.5811,  1.9613],\n",
       "                        [ 1.3615,  1.5362,  1.8857]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.2961, -1.1403, -1.2000],\n",
       "                        [-1.1517, -1.2445, -1.2034],\n",
       "                        [-1.2067, -1.2492, -1.1817]],\n",
       "              \n",
       "                       [[-1.2536, -1.2026, -1.1908],\n",
       "                        [-1.2160, -1.2753, -1.2031],\n",
       "                        [-1.2025, -1.1885, -1.2428]],\n",
       "              \n",
       "                       [[-1.1692, -1.2602, -1.1955],\n",
       "                        [-1.2391, -1.1723,  1.1540],\n",
       "                        [-1.1549, -1.2418, -1.1414]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.2817, -1.1723, -1.1436],\n",
       "                        [-1.2050, -1.1757, -1.2121],\n",
       "                        [-1.2179, -1.2404, -1.1903]],\n",
       "              \n",
       "                       [[ 1.1878,  1.1209, -1.2395],\n",
       "                        [ 1.2050,  1.1301, -1.1698],\n",
       "                        [ 1.1267,  1.1286, -1.1901]],\n",
       "              \n",
       "                       [[-1.2814, -1.2449, -1.2061],\n",
       "                        [ 1.1625, -1.2323,  1.1573],\n",
       "                        [-1.1748, -1.1299, -1.1220]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-1.1005, -1.1411, -1.1611],\n",
       "                        [-1.2311, -1.1556, -1.1399],\n",
       "                        [-1.2226, -1.0828, -1.1640]],\n",
       "              \n",
       "                       [[-0.9218, -1.2651, -0.8797],\n",
       "                        [-0.8508, -1.3059, -1.0050],\n",
       "                        [-0.9203, -1.3957, -0.9273]],\n",
       "              \n",
       "                       [[-1.1336, -1.1996, -1.2188],\n",
       "                        [-1.1287, -1.2768, -1.3288],\n",
       "                        [-1.2731, -1.1693, -1.2282]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.7377,  0.7012,  0.8249],\n",
       "                        [ 0.6372,  0.7401,  0.7912],\n",
       "                        [ 0.6510,  0.7279,  0.6989]],\n",
       "              \n",
       "                       [[ 0.6869,  0.6418,  1.1265],\n",
       "                        [ 0.5251,  0.5156,  0.9535],\n",
       "                        [ 0.5455,  0.6017,  1.1062]],\n",
       "              \n",
       "                       [[ 1.3173,  1.1868,  1.2610],\n",
       "                        [ 1.1723,  1.2214,  1.2065],\n",
       "                        [ 1.2081,  1.3118,  1.3229]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.7668,  0.7665,  0.4961],\n",
       "                        [ 0.6703,  0.6928,  1.0291],\n",
       "                        [ 1.0286,  0.6793,  0.9340]],\n",
       "              \n",
       "                       [[-0.7238, -1.1149, -0.8285],\n",
       "                        [-1.0537, -1.1046, -1.1663],\n",
       "                        [-0.6125, -0.5545, -0.7427]],\n",
       "              \n",
       "                       [[ 0.6934,  0.6990,  1.0662],\n",
       "                        [ 0.7731,  0.6967,  0.5058],\n",
       "                        [ 1.1661,  1.1661,  0.8827]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.7381,  0.6862,  0.6080],\n",
       "                        [ 0.6432,  0.5999,  0.8072],\n",
       "                        [ 1.0967,  0.4954,  0.9352]],\n",
       "              \n",
       "                       [[ 1.3452,  1.2853,  0.8710],\n",
       "                        [ 0.9071,  0.6967,  0.6291],\n",
       "                        [ 1.3612,  1.2149,  1.1481]],\n",
       "              \n",
       "                       [[ 0.9760,  0.8752,  0.7945],\n",
       "                        [ 0.6978,  0.8216,  0.7744],\n",
       "                        [ 0.8187,  0.7253,  0.7807]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.8984, -1.2825, -1.3620],\n",
       "                        [-0.0573, -1.3623, -1.3018],\n",
       "                        [ 0.0968, -1.2566, -1.3580]],\n",
       "              \n",
       "                       [[-1.0011, -1.2168, -1.2888],\n",
       "                        [ 1.1271, -1.2572, -1.2113],\n",
       "                        [ 1.1503, -1.2439, -1.2527]],\n",
       "              \n",
       "                       [[-1.5209, -1.2083, -1.1863],\n",
       "                        [-0.4277, -1.2185, -1.2606],\n",
       "                        [-0.4031, -1.3903, -1.1672]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.5039, -1.2623, -1.1783],\n",
       "                        [-0.1953, -1.1427, -1.2366],\n",
       "                        [-0.5123, -1.2613, -1.1748]],\n",
       "              \n",
       "                       [[-0.6994, -1.2017, -1.2422],\n",
       "                        [-0.6842, -1.2872, -1.1628],\n",
       "                        [-0.5037, -1.7398, -1.2023]],\n",
       "              \n",
       "                       [[-0.7477, -1.2809, -1.2478],\n",
       "                        [-1.0888, -1.2369, -1.2114],\n",
       "                        [-1.6981, -1.2716, -1.1538]]]])),\n",
       "             ('conv2.bias',\n",
       "              tensor([ 1.7611, -2.1781, -1.1641, -1.1732, -1.2304,  1.2969, -1.0927,  1.5238,\n",
       "                      -0.9102,  0.9726,  1.3697, -1.1935,  1.4250,  1.5608, -1.1986,  1.6498,\n",
       "                       1.4771,  1.3337, -0.5904, -1.6783])),\n",
       "             ('conv3.weight',\n",
       "              tensor([[[[ 0.9849,  1.0337,  2.0570],\n",
       "                        [ 0.6513,  1.0143,  2.0209],\n",
       "                        [ 0.5444, -0.0367,  1.3019]],\n",
       "              \n",
       "                       [[ 0.1343,  1.2340, -1.7683],\n",
       "                        [-0.3616,  1.2035, -1.6078],\n",
       "                        [ 0.0997,  1.2724,  0.6392]],\n",
       "              \n",
       "                       [[-1.1608, -1.2472, -1.1474],\n",
       "                        [ 1.2534, -1.1895, -1.2018],\n",
       "                        [ 1.2505, -1.2395,  1.2203]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1675, -0.3069,  0.3824],\n",
       "                        [-0.8317, -0.4066,  0.2392],\n",
       "                        [-0.5114, -0.4716,  0.2455]],\n",
       "              \n",
       "                       [[ 0.5230,  0.9186,  1.4565],\n",
       "                        [ 0.0157,  0.7882,  1.6266],\n",
       "                        [ 0.0478,  0.2775,  1.4052]],\n",
       "              \n",
       "                       [[-1.2280,  1.2614,  1.1741],\n",
       "                        [-1.1777,  1.2205, -0.1469],\n",
       "                        [-1.2245,  1.2483,  1.4987]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.6986, -0.3866, -0.1089],\n",
       "                        [-0.2317, -1.1494, -0.8074],\n",
       "                        [ 0.0447, -1.3121, -0.9052]],\n",
       "              \n",
       "                       [[ 1.6803,  2.6790,  2.5762],\n",
       "                        [ 1.7231,  2.6738,  2.5548],\n",
       "                        [ 1.3710,  2.7674,  2.6051]],\n",
       "              \n",
       "                       [[ 1.2042,  1.2359,  1.2511],\n",
       "                        [ 1.1924,  1.2328,  1.1554],\n",
       "                        [ 1.2502,  1.1818,  1.2194]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.7687,  1.4930,  1.0308],\n",
       "                        [ 1.6590,  1.2824,  0.6154],\n",
       "                        [ 1.3232,  1.2901,  0.4896]],\n",
       "              \n",
       "                       [[ 0.5284,  0.2590,  0.1449],\n",
       "                        [ 0.3936,  0.1615,  0.1221],\n",
       "                        [ 0.7303,  0.1883,  0.0846]],\n",
       "              \n",
       "                       [[-0.9255,  1.2805, -0.5600],\n",
       "                        [-1.1250,  1.3694, -1.4747],\n",
       "                        [ 1.5086,  1.2744,  1.5045]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.9216, -0.8333, -0.2013],\n",
       "                        [-0.5744, -0.7236, -0.5085],\n",
       "                        [-1.4392, -0.4501, -0.2505]],\n",
       "              \n",
       "                       [[ 1.0316,  1.6215,  1.4835],\n",
       "                        [ 1.0283,  1.5322,  1.4168],\n",
       "                        [ 1.0069,  1.5300,  1.4219]],\n",
       "              \n",
       "                       [[-1.1817, -1.1790, -1.1706],\n",
       "                        [-1.2653,  1.2150,  1.1567],\n",
       "                        [ 1.2626,  1.1461, -1.1898]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.2876, -1.2356, -1.1679],\n",
       "                        [-1.3281, -1.2462, -1.1267],\n",
       "                        [-1.3371, -1.3389, -1.3299]],\n",
       "              \n",
       "                       [[-1.2733, -1.2226, -1.2085],\n",
       "                        [-1.2577, -1.2210, -1.2318],\n",
       "                        [-1.3419, -1.3437, -1.2386]],\n",
       "              \n",
       "                       [[-1.0119, -0.0113, -0.5415],\n",
       "                        [-1.6325, -1.5090, -1.6739],\n",
       "                        [-0.7240, -0.5925, -0.6826]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0984,  0.8044,  0.3466],\n",
       "                        [-0.1924,  1.2048,  0.6107],\n",
       "                        [-0.0867,  0.3580,  0.0655]],\n",
       "              \n",
       "                       [[ 1.7962, -0.3182, -1.5843],\n",
       "                        [ 1.9345, -0.4246, -1.5376],\n",
       "                        [ 1.8154, -0.5436, -1.5581]],\n",
       "              \n",
       "                       [[-1.2153,  1.2495, -1.1656],\n",
       "                        [-1.2213, -1.2059, -1.2608],\n",
       "                        [ 1.1483,  1.1425, -1.2157]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.7689, -0.8207, -0.7685],\n",
       "                        [-0.7642, -0.7719, -1.2300],\n",
       "                        [-0.7560, -0.7965, -1.3066]],\n",
       "              \n",
       "                       [[-0.3565, -0.3835, -0.5961],\n",
       "                        [-0.3106, -0.3286, -0.6240],\n",
       "                        [-0.3282, -0.4759, -0.6421]],\n",
       "              \n",
       "                       [[ 1.3128, -1.4934, -0.3238],\n",
       "                        [ 1.8013,  1.2375,  0.9204],\n",
       "                        [ 1.2548,  0.4379, -2.0305]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.4748, -1.6083, -1.4837],\n",
       "                        [-1.0588, -1.7346, -0.9616],\n",
       "                        [-1.2383, -0.8253,  0.0642]],\n",
       "              \n",
       "                       [[-0.9909,  1.5971,  1.3907],\n",
       "                        [-0.9769,  1.6418,  1.3827],\n",
       "                        [-1.1233,  1.4025,  1.4761]],\n",
       "              \n",
       "                       [[ 1.1870,  1.2348,  1.1769],\n",
       "                        [ 1.2181,  1.2057,  1.2621],\n",
       "                        [ 1.1719,  1.1509, -1.1382]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.3652, -1.0759, -0.9510],\n",
       "                        [-1.4635, -0.9686, -1.0306],\n",
       "                        [-1.4949, -1.0108, -1.0255]],\n",
       "              \n",
       "                       [[ 0.7653,  0.5489,  0.5885],\n",
       "                        [ 0.9438,  0.7627,  0.6379],\n",
       "                        [ 1.3860,  0.7388,  0.7273]],\n",
       "              \n",
       "                       [[-0.4192,  1.0385, -1.7371],\n",
       "                        [-0.9020,  1.1082, -1.6283],\n",
       "                        [-1.7642,  1.0204, -0.4991]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.4989, -1.5163, -0.5133],\n",
       "                        [ 0.9948, -1.6418, -1.3976],\n",
       "                        [ 1.6461, -0.9246, -0.8162]],\n",
       "              \n",
       "                       [[-1.3409, -1.2101,  1.2196],\n",
       "                        [-1.3148, -1.2025,  1.1826],\n",
       "                        [-1.2957, -1.1661,  1.2634]],\n",
       "              \n",
       "                       [[ 1.1365, -1.2236, -1.2596],\n",
       "                        [-1.2358, -1.2489, -1.2587],\n",
       "                        [ 1.1454, -1.2340, -1.1374]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.2463, -1.4871, -1.6863],\n",
       "                        [-1.3543, -1.5711, -1.7198],\n",
       "                        [-0.8689, -1.6220, -1.3817]],\n",
       "              \n",
       "                       [[ 1.4644, -0.6925, -1.1239],\n",
       "                        [ 1.5199, -0.5300, -0.9142],\n",
       "                        [ 1.6738, -0.5684, -0.7693]],\n",
       "              \n",
       "                       [[-0.7496, -1.2493, -0.9828],\n",
       "                        [-1.7110, -1.2416,  1.2733],\n",
       "                        [-1.6785, -1.4519, -1.4007]]]])),\n",
       "             ('conv3.bias',\n",
       "              tensor([-0.7937, -1.3358,  1.3655,  1.1849, -0.5916, -1.1907,  1.6519,  1.3569,\n",
       "                      -0.9806, -0.5772,  0.9326, -0.8046, -1.2473,  1.1380, -1.0905,  1.6596,\n",
       "                      -1.0458,  1.2449, -0.9104, -0.6352,  1.2747, -1.2442,  0.9987,  1.0238,\n",
       "                       0.0626,  0.9900,  0.8941, -0.9128, -0.9662, -1.4821, -2.4238, -0.8258])),\n",
       "             ('bn3.weight',\n",
       "              tensor([-0.8638, -0.4618, -0.6129, -1.0657, -0.3987, -0.9731, -0.4710, -0.6826,\n",
       "                      -0.5304, -0.3834, -0.4913, -0.6170, -0.4127, -0.5523, -0.7689, -0.7830,\n",
       "                      -0.7742, -0.3460, -0.5396, -0.4824, -0.4877, -0.3618, -0.7172, -0.6840,\n",
       "                      -0.3719, -0.6952, -1.1148, -0.3039, -0.3982, -0.6701, -1.0765, -0.3317])),\n",
       "             ('bn3.bias',\n",
       "              tensor([-1.7508, -2.0791, -1.9674, -2.2527, -2.3616, -1.9827, -1.5159, -1.5270,\n",
       "                      -1.7493, -1.7045, -1.9338, -1.8829, -1.4206, -1.5907, -1.8914, -1.8187,\n",
       "                      -1.7719, -1.8754, -2.2463, -2.0711, -1.5238, -1.3661, -1.8611, -1.7249,\n",
       "                      -1.5811, -1.4226, -2.1187, -2.5280, -1.5628, -1.8797, -1.6690, -1.3661])),\n",
       "             ('bn3.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('bn3.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('bn3.num_batches_tracked', tensor(100)),\n",
       "             ('fc.weight',\n",
       "              tensor([[-1.3165e+00, -8.1903e-01, -9.4586e-01,  ..., -1.1962e+00,\n",
       "                       -1.2001e+00, -1.3293e-03],\n",
       "                      [ 1.3162e+00,  8.1761e-01,  9.4559e-01,  ...,  1.1961e+00,\n",
       "                        1.1996e+00,  9.2048e-04]])),\n",
       "             ('fc.bias', tensor([-0.2058,  0.2048]))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote_model_1_updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5cc2a351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['conv1.weight', 'conv1.bias', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'conv2.weight', 'conv2.bias', 'conv3.weight', 'conv3.bias', 'bn3.weight', 'bn3.bias', 'bn3.running_mean', 'bn3.running_var', 'bn3.num_batches_tracked', 'fc.weight', 'fc.bias'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote_model_1_updates.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1200835d",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_model_2_updates = remote_model_2.get(\n",
    "    request_block=True\n",
    ").state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a9ad182",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_model_3_updates = remote_model_3.get(\n",
    "    request_block=True\n",
    ").state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a825eba",
   "metadata": {},
   "source": [
    "# Average Updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "194f0582",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_updates = OrderedDict()\n",
    "for key in remote_model_1_updates.keys():\n",
    "    avg_updates[key] = (\n",
    "        (remote_model_1_updates[key] +\n",
    "        remote_model_2_updates[key] +\n",
    "        remote_model_3_updates[key]) / 3\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfa9003",
   "metadata": {},
   "source": [
    "# Load Average Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "159be137",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_model = classify(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91c215f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_model.load_state_dict(avg_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa91820f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregated_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb3583c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del avg_updates, remote_model_1_updates, remote_model_2_updates, remote_model_3_updates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def1ecd5",
   "metadata": {},
   "source": [
    "# Test the Agregated Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b7097227",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIL_to_Tensor = transforms.Compose([\n",
    "                transforms.Resize(size = (224,224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "deb17b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = datasets.ImageFolder('chest_xray/test', transform= PIL_to_Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ba4ba95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "test_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0a85b6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(0, 300):\n",
    "    data_image = test_images[index][0].type(torch.long).numpy()\n",
    "    test_data.append(data_image)\n",
    "    test_labels.append(test_images[index][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "72cba226",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = torch.FloatTensor(test_data)\n",
    "test_labels = torch.FloatTensor(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9904c432",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.tag(\"#Aggragted_Model_X\")\n",
    "test_labels = test_labels.tag(\"#Aggragted_Model_X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5191b607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_data)):\n",
    "        sample = test_data[i].view(1, 3, 224, 224)\n",
    "        y_hat = aggregated_model(sample)\n",
    "        prediction = float(y_hat.argmax(dim=1).item())\n",
    "        label = test_labels[i].item()\n",
    "        if prediction == label:\n",
    "            count += 1\n",
    "            \n",
    "print(f\"Accuracy: {count/len(test_data)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
